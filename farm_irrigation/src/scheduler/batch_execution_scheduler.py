#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹æ¬¡æ‰§è¡Œè°ƒåº¦å™¨ - åŠ¨æ€æ°´ä½æ›´æ–°çŒæº‰ç³»ç»Ÿ

åŠŸèƒ½ï¼š
1. ç›‘æ§æ‰¹æ¬¡æ‰§è¡Œæ—¶æœº
2. åœ¨æ¯ä¸ªæ‰¹æ¬¡å¼€å§‹å‰è·å–æœ€æ–°æ°´ä½è¯»æ•°
3. åŸºäºæ–°æ°´ä½é‡æ–°è®¡ç®—æ‰¹æ¬¡æ‰§è¡Œå†…å®¹
4. æ§åˆ¶å®é™…çš„è®¾å¤‡æ‰§è¡Œ
"""

import asyncio
import json
import logging
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field
from enum import Enum

# å¯¼å…¥ç°æœ‰æ¨¡å—
try:
    from src.api.waterlevel_api import fetch_waterlevels
except ImportError:
    try:
        from mock_waterlevel_api import fetch_waterlevels
    except ImportError:
        fetch_waterlevels = None

from src.core.farm_irr_full_device_modified import (
    farmcfg_from_json_select, 
    build_concurrent_plan, 
    plan_to_json
)
from .dynamic_waterlevel_manager import DynamicWaterLevelManager
from .dynamic_plan_regenerator import DynamicPlanRegenerator
from .execution_status_manager import ExecutionStatusManager, ExecutionStatus, get_status_manager

# é…ç½®æ—¥å¿—ï¼ˆä¿®å¤ç¼–ç é—®é¢˜ï¼‰
import os
# åŸºäºé¡¹ç›®æ ¹ç›®å½•è®¡ç®—æ—¥å¿—è·¯å¾„
_log_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'data', 'execution_logs')
_log_dir = os.path.abspath(_log_dir)
os.makedirs(_log_dir, exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(os.path.join(_log_dir, 'batch_execution_scheduler.log'), encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class BatchStatus(Enum):
    """æ‰¹æ¬¡çŠ¶æ€æšä¸¾"""
    PENDING = "pending"          # ç­‰å¾…æ‰§è¡Œ
    PREPARING = "preparing"      # å‡†å¤‡ä¸­ï¼ˆè·å–æ°´ä½ã€é‡æ–°è®¡ç®—ï¼‰
    EXECUTING = "executing"      # æ‰§è¡Œä¸­
    COMPLETED = "completed"      # å·²å®Œæˆ
    FAILED = "failed"           # æ‰§è¡Œå¤±è´¥
    CANCELLED = "cancelled"     # å·²å–æ¶ˆ

@dataclass
class BatchExecution:
    """æ‰¹æ¬¡æ‰§è¡Œä¿¡æ¯"""
    batch_index: int
    original_start_time: float  # åŸå§‹å¼€å§‹æ—¶é—´ï¼ˆå°æ—¶ï¼‰
    original_duration: float    # åŸå§‹æŒç»­æ—¶é—´ï¼ˆå°æ—¶ï¼‰
    current_start_time: Optional[float] = None  # å½“å‰å¼€å§‹æ—¶é—´
    current_duration: Optional[float] = None    # å½“å‰æŒç»­æ—¶é—´
    status: BatchStatus = BatchStatus.PENDING
    original_plan: Optional[Dict[str, Any]] = None
    updated_plan: Optional[Dict[str, Any]] = None
    water_levels: Optional[Dict[str, float]] = None
    execution_log: List[str] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.now)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    error_message: Optional[str] = None

class BatchExecutionScheduler:
    """æ‰¹æ¬¡æ‰§è¡Œè°ƒåº¦å™¨"""
    
    def __init__(self, 
                 config_path: str = None,
                 farm_id: str = "default_farm",
                 enable_realtime_waterlevels: bool = True,
                 pre_execution_buffer_minutes: int = 5,
                 app_id: str = None,
                 secret: str = None):
        """
        åˆå§‹åŒ–è°ƒåº¦å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¸ºNoneï¼Œåˆ™åŸºäºé¡¹ç›®æ ¹ç›®å½•è®¡ç®—ï¼‰
            farm_id: å†œåœºIDï¼Œç”¨äºè·å–æ°´ä½æ•°æ®
            enable_realtime_waterlevels: æ˜¯å¦å¯ç”¨å®æ—¶æ°´ä½è·å–
            pre_execution_buffer_minutes: æ‰¹æ¬¡æ‰§è¡Œå‰çš„ç¼“å†²æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
            app_id: iLandå¹³å°åº”ç”¨ID
            secret: iLandå¹³å°å¯†é’¥
        """
        # å¦‚æœæœªæŒ‡å®šè·¯å¾„ï¼ŒåŸºäºé¡¹ç›®æ ¹ç›®å½•è®¡ç®—
        if config_path is None:
            project_root = Path(__file__).parent.parent.parent
            config_path = str(project_root / "config.json")
        
        self.config_path = Path(config_path)
        self.farm_id = farm_id
        self.enable_realtime_waterlevels = enable_realtime_waterlevels
        self.pre_execution_buffer_minutes = pre_execution_buffer_minutes
        
        # iLandå¹³å°è®¤è¯
        import os
        self.app_id = app_id or os.getenv("ILAND_APP_ID", "")
        self.secret = secret or os.getenv("ILAND_SECRET", "")
        
        # æ‰§è¡ŒçŠ¶æ€
        self.is_running = False
        self.execution_id: Optional[str] = None
        self.execution_status: str = "idle"  # idle, running, completed, error
        self.current_plan: Optional[Dict[str, Any]] = None
        self.raw_plan_data: Optional[Dict[str, Any]] = None  # å­˜å‚¨åŸå§‹å®Œæ•´è®¡åˆ’æ•°æ®
        self.selected_scenario_name: Optional[str] = None  # å½“å‰é€‰ä¸­çš„æ–¹æ¡ˆåç§°
        self.batch_executions: Dict[int, BatchExecution] = {}
        self.execution_start_time: Optional[datetime] = None
        self.current_batch_index: int = 0
        self.total_regenerations: int = 0
        self.last_water_level_update: Optional[str] = None
        self.error_message: Optional[str] = None
        
        # å›è°ƒå‡½æ•°
        self.device_control_callback: Optional[Callable] = None
        self.status_update_callback: Optional[Callable] = None
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.status_manager = get_status_manager()
        
        # è®¾å¤‡æŒ‡ä»¤é˜Ÿåˆ—
        from .device_command_queue import DeviceCommandQueue
        self.command_queue = DeviceCommandQueue()
        
        # ç”°å—å®Œæˆåº¦ç›‘æ§å™¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self.completion_monitor = None
        
        # åŠ è½½é…ç½®
        self._load_config()
    
    def get_farm_id(self) -> str:
        """è·å–å†œåœºID"""
        return self.farm_id
    
    def _load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            if self.config_path.exists():
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    self.config_data = json.load(f)
                logger.info(f"é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {self.config_path}")
            else:
                logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
                self.config_data = {}
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            self.config_data = {}
    
    async def load_config(self, config_path: str):
        """
        å¼‚æ­¥åŠ è½½é…ç½®æ–‡ä»¶
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = Path(config_path)
        self._load_config()
    
    def load_irrigation_plan(self, plan_path: str) -> bool:
        """
        åŠ è½½çŒæº‰è®¡åˆ’
        
        Args:
            plan_path: è®¡åˆ’æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            plan_file = Path(plan_path)
            if not plan_file.exists():
                logger.error(f"è®¡åˆ’æ–‡ä»¶ä¸å­˜åœ¨: {plan_path}")
                return False

            with open(plan_file, 'r', encoding='utf-8') as f:
                raw_data = json.load(f)
            
            # ä¿å­˜åŸå§‹å®Œæ•´æ•°æ®
            self.raw_plan_data = raw_data
            
            # æ£€æŸ¥æ–‡ä»¶ç»“æ„å¹¶æå–å®é™…çš„è®¡åˆ’æ•°æ®
            if "scenarios" in raw_data and raw_data["scenarios"]:
                # æ–°æ ¼å¼ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªscenarioçš„plan
                selected_scenario = raw_data["scenarios"][0]
                self.current_plan = selected_scenario["plan"]
                self.selected_scenario_name = selected_scenario.get("scenario_name", "Unknown")
                logger.info(f"ä½¿ç”¨scenariosæ ¼å¼ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªscenario: {self.selected_scenario_name}")
            elif "batches" in raw_data and "steps" in raw_data:
                # æ—§æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨æ ¹çº§åˆ«çš„æ•°æ®
                self.current_plan = raw_data
                self.selected_scenario_name = "Default Plan"
                logger.info("ä½¿ç”¨ä¼ ç»Ÿæ ¼å¼çš„è®¡åˆ’æ–‡ä»¶")
            else:
                logger.error(f"æ— æ³•è¯†åˆ«çš„è®¡åˆ’æ–‡ä»¶æ ¼å¼: {plan_path}")
                return False

            # è§£ææ‰¹æ¬¡ä¿¡æ¯
            self._parse_batches()

            logger.info(f"çŒæº‰è®¡åˆ’åŠ è½½æˆåŠŸ: {plan_path}")
            logger.info(f"å…±æœ‰ {len(self.batch_executions)} ä¸ªæ‰¹æ¬¡")

            return True

        except Exception as e:
            logger.error(f"åŠ è½½çŒæº‰è®¡åˆ’å¤±è´¥: {e}")
            return False
    
    def _parse_batches(self):
        """è§£ææ‰¹æ¬¡ä¿¡æ¯"""
        self.batch_executions.clear()
        
        if not self.current_plan:
            return
        
        batches = self.current_plan.get("batches", [])
        steps = self.current_plan.get("steps", [])
        
        for batch in batches:
            batch_index = batch.get("index")
            if batch_index is None:
                continue
            
            # ä»stepsä¸­æ‰¾åˆ°å¯¹åº”çš„æ—¶é—´ä¿¡æ¯
            start_time = 0.0
            duration = 1.0  # é»˜è®¤1å°æ—¶
            
            batch_label = f"æ‰¹æ¬¡ {batch_index}"
            for step in steps:
                if step.get("label") == batch_label:
                    start_time = step.get("t_start_h", 0.0)
                    end_time = step.get("t_end_h", 1.0)
                    duration = end_time - start_time
                    break
            
            # åˆ›å»ºæ‰¹æ¬¡æ‰§è¡Œå¯¹è±¡
            batch_execution = BatchExecution(
                batch_index=batch_index,
                original_start_time=start_time,
                original_duration=duration,
                original_plan=batch.copy()
            )
            
            self.batch_executions[batch_index] = batch_execution
            
            logger.info(f"æ‰¹æ¬¡ {batch_index}: å¼€å§‹æ—¶é—´ {start_time:.2f}h, æŒç»­æ—¶é—´ {duration:.2f}h")
    
    async def start_execution(self) -> bool:
        """
        å¼€å§‹æ‰§è¡ŒçŒæº‰è®¡åˆ’
        
        Returns:
            bool: æ˜¯å¦å¯åŠ¨æˆåŠŸ
        """
        if self.is_running:
            self.status_manager.log_warning("scheduler", "è°ƒåº¦å™¨å·²åœ¨è¿è¡Œä¸­")
            return False
        
        if not self.current_plan or not self.batch_executions:
            self.status_manager.log_error("scheduler", "æ²¡æœ‰å¯æ‰§è¡Œçš„çŒæº‰è®¡åˆ’")
            return False
        
        # è®¾ç½®æ‰§è¡ŒçŠ¶æ€
        self.is_running = True
        self.execution_start_time = datetime.now()
        self.execution_id = f"exec_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.execution_status = "running"
        self.current_batch_index = 0
        self.error_message = None
        
        # æ›´æ–°çŠ¶æ€
        batch_id = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        # ä½¿ç”¨update_execution_statusè€Œä¸æ˜¯ä¸å­˜åœ¨çš„start_executionæ–¹æ³•
        self.status_manager.update_execution_status(
            farm_id=batch_id,
            batch_index=1,  # å¼€å§‹æ‰§è¡Œæ—¶ä½¿ç”¨æ‰¹æ¬¡1
            status=ExecutionStatus.RUNNING,
            total_batches=len(self.batch_executions),
            current_batch=0
        )
        self.status_manager.log_info("scheduler", f"å¼€å§‹æ‰§è¡ŒçŒæº‰è®¡åˆ’ï¼Œæ‰§è¡ŒID: {self.execution_id}")
        self.status_manager.log_info("scheduler", f"æ‰§è¡Œå¼€å§‹æ—¶é—´: {self.execution_start_time}")
        
        try:
            # åœ¨åå°å¯åŠ¨ä¸»æ‰§è¡Œå¾ªç¯ï¼Œä¸é˜»å¡å½“å‰è°ƒç”¨
            import asyncio
            asyncio.create_task(self._execution_loop())
            
        except Exception as e:
            self.status_manager.log_error("scheduler", f"å¯åŠ¨æ‰§è¡Œå¾ªç¯å¤±è´¥: {e}")
            self.is_running = False
            self.execution_status = "error"
            self.error_message = str(e)
            return False
        
        return True
    
    async def _execution_loop(self):
        """ä¸»æ‰§è¡Œå¾ªç¯"""
        while self.is_running and self._has_pending_batches():
            current_time = datetime.now()
            elapsed_hours = (current_time - self.execution_start_time).total_seconds() / 3600
            
            # æ£€æŸ¥éœ€è¦å‡†å¤‡çš„æ‰¹æ¬¡
            for batch_index, batch_exec in self.batch_executions.items():
                if batch_exec.status == BatchStatus.PENDING:
                    # è®¡ç®—æ˜¯å¦éœ€è¦å¼€å§‹å‡†å¤‡
                    time_to_start = batch_exec.original_start_time - elapsed_hours
                    buffer_hours = self.pre_execution_buffer_minutes / 60
                    
                    if time_to_start <= buffer_hours:
                        logger.info(f"å¼€å§‹å‡†å¤‡æ‰¹æ¬¡ {batch_index}")
                        await self._prepare_batch(batch_exec)
            
            # æ£€æŸ¥éœ€è¦æ‰§è¡Œçš„æ‰¹æ¬¡
            for batch_index, batch_exec in self.batch_executions.items():
                if batch_exec.status == BatchStatus.PREPARING:
                    # æ£€æŸ¥æ˜¯å¦åˆ°äº†æ‰§è¡Œæ—¶é—´
                    time_to_start = batch_exec.original_start_time - elapsed_hours
                    
                    if time_to_start <= 0:
                        logger.info(f"å¼€å§‹æ‰§è¡Œæ‰¹æ¬¡ {batch_index}")
                        await self._execute_batch(batch_exec)
            
            # æ£€æŸ¥æ­£åœ¨æ‰§è¡Œçš„æ‰¹æ¬¡æ˜¯å¦å®Œæˆ
            for batch_index, batch_exec in self.batch_executions.items():
                if batch_exec.status == BatchStatus.EXECUTING:
                    await self._check_batch_completion(batch_exec, elapsed_hours)
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´åå†æ¬¡æ£€æŸ¥
            await asyncio.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
        
        # æ‰§è¡Œå®Œæˆï¼Œæ›´æ–°çŠ¶æ€
        logger.info("æ‰€æœ‰æ‰¹æ¬¡æ‰§è¡Œå®Œæˆ")
        self.is_running = False
        self.execution_status = "completed"
    
    def _has_pending_batches(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¾…æ‰§è¡Œçš„æ‰¹æ¬¡"""
        for batch_exec in self.batch_executions.values():
            if batch_exec.status in [BatchStatus.PENDING, BatchStatus.PREPARING, BatchStatus.EXECUTING]:
                return True
        return False
    
    async def _prepare_batch(self, batch_exec: BatchExecution):
        """
        å‡†å¤‡æ‰¹æ¬¡æ‰§è¡Œ
        
        Args:
            batch_exec: æ‰¹æ¬¡æ‰§è¡Œå¯¹è±¡
        """
        try:
            batch_exec.status = BatchStatus.PREPARING
            batch_exec.execution_log.append(f"å¼€å§‹å‡†å¤‡æ‰¹æ¬¡ {batch_exec.batch_index}")
            
            # 1. è·å–æœ€æ–°æ°´ä½æ•°æ®
            if self.enable_realtime_waterlevels:
                water_levels = await self._fetch_current_water_levels()
                batch_exec.water_levels = water_levels
                batch_exec.execution_log.append(f"è·å–åˆ° {len(water_levels)} ä¸ªç”°å—çš„æ°´ä½æ•°æ®")
            
            # 2. åŸºäºæ–°æ°´ä½é‡æ–°ç”Ÿæˆæ‰¹æ¬¡è®¡åˆ’
            updated_plan = await self._regenerate_batch_plan(batch_exec)
            batch_exec.updated_plan = updated_plan
            
            # 3. æ›´æ–°æ‰§è¡Œæ—¶é—´ï¼ˆå¦‚æœéœ€è¦ï¼‰
            batch_exec.current_start_time = batch_exec.original_start_time
            batch_exec.current_duration = batch_exec.original_duration
            
            batch_exec.execution_log.append(f"æ‰¹æ¬¡ {batch_exec.batch_index} å‡†å¤‡å®Œæˆ")
            
            # é€šçŸ¥çŠ¶æ€æ›´æ–°
            if self.status_update_callback:
                await self.status_update_callback(batch_exec)
                
        except Exception as e:
            batch_exec.status = BatchStatus.FAILED
            batch_exec.error_message = str(e)
            batch_exec.execution_log.append(f"å‡†å¤‡æ‰¹æ¬¡å¤±è´¥: {e}")
            logger.error(f"å‡†å¤‡æ‰¹æ¬¡ {batch_exec.batch_index} å¤±è´¥: {e}")
    
    async def _fetch_current_water_levels(self) -> Dict[str, float]:
        """
        è·å–å½“å‰æ°´ä½æ•°æ®
        
        Returns:
            Dict[str, float]: ç”°å—IDåˆ°æ°´ä½çš„æ˜ å°„
        """
        water_levels = {}
        
        try:
            if callable(fetch_waterlevels):
                # è°ƒç”¨æ°´ä½APIè·å–æ•°æ®
                realtime_rows = fetch_waterlevels(self.farm_id)
                
                if realtime_rows:
                    # è§£ææ°´ä½æ•°æ®
                    for row in realtime_rows:
                        field_id = row.get("field_id") or row.get("sectionID") or row.get("id")
                        water_level = row.get("waterlevel_mm") or row.get("water_level")
                        
                        if field_id and water_level is not None:
                            try:
                                water_levels[str(field_id)] = float(water_level)
                            except (ValueError, TypeError):
                                continue
                
                # æ›´æ–°æœ€åæ°´ä½æ›´æ–°æ—¶é—´
                self.last_water_level_update = datetime.now().isoformat()
                logger.info(f"ä»APIè·å–åˆ° {len(water_levels)} ä¸ªæ°´ä½æ•°æ®")
            else:
                logger.warning("æ°´ä½APIä¸å¯ç”¨ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æ°´ä½")
                
        except Exception as e:
            logger.error(f"è·å–æ°´ä½æ•°æ®å¤±è´¥: {e}")
        
        return water_levels
    
    async def _regenerate_batch_plan(self, batch_exec: BatchExecution) -> Dict[str, Any]:
        """
        åŸºäºæ–°æ°´ä½é‡æ–°ç”Ÿæˆæ‰¹æ¬¡è®¡åˆ’
        
        Args:
            batch_exec: æ‰¹æ¬¡æ‰§è¡Œå¯¹è±¡
            
        Returns:
            Dict[str, Any]: æ›´æ–°åçš„æ‰¹æ¬¡è®¡åˆ’
        """
        try:
            # å‡†å¤‡è‡ªå®šä¹‰æ°´ä½æ•°æ®
            custom_waterlevels = None
            if batch_exec.water_levels:
                custom_waterlevels = json.dumps(batch_exec.water_levels)
            
            # é‡æ–°ç”Ÿæˆé…ç½®
            cfg = farmcfg_from_json_select(
                self.config_data,
                active_pumps=None,  # ä½¿ç”¨é»˜è®¤æ°´æ³µé…ç½®
                zone_ids=None,      # ä½¿ç”¨é»˜è®¤åŒºåŸŸé…ç½®
                use_realtime_wl=True,
                custom_waterlevels=custom_waterlevels
            )
            
            # é‡æ–°ç”Ÿæˆè®¡åˆ’
            new_plan = build_concurrent_plan(cfg)
            new_plan_json = plan_to_json(new_plan)
            
            # æ›´æ–°é‡æ–°ç”Ÿæˆè®¡æ•°
            self.total_regenerations += 1
            
            logger.info(f"æ‰¹æ¬¡ {batch_exec.batch_index} è®¡åˆ’é‡æ–°ç”Ÿæˆå®Œæˆ")
            
            return new_plan_json
            
        except Exception as e:
            logger.error(f"é‡æ–°ç”Ÿæˆæ‰¹æ¬¡è®¡åˆ’å¤±è´¥: {e}")
            # å¦‚æœé‡æ–°ç”Ÿæˆå¤±è´¥ï¼Œè¿”å›åŸå§‹è®¡åˆ’
            return batch_exec.original_plan or {}
    
    async def _execute_batch(self, batch_exec: BatchExecution):
        """
        æ‰§è¡Œæ‰¹æ¬¡ï¼ˆå¢å¼ºç‰ˆ - é›†æˆå®æ—¶ç›‘æ§ï¼‰
        
        Args:
            batch_exec: æ‰¹æ¬¡æ‰§è¡Œå¯¹è±¡
        """
        try:
            batch_exec.status = BatchStatus.EXECUTING
            batch_exec.started_at = datetime.now()
            batch_exec.execution_log.append(f"å¼€å§‹æ‰§è¡Œæ‰¹æ¬¡ {batch_exec.batch_index}")
            
            # æ›´æ–°å½“å‰æ‰¹æ¬¡ç´¢å¼•
            self.current_batch_index = batch_exec.batch_index
            
            # ä½¿ç”¨æ›´æ–°åçš„è®¡åˆ’æˆ–åŸå§‹è®¡åˆ’
            plan_to_execute = batch_exec.updated_plan or batch_exec.original_plan
            
            # 1. ç”Ÿæˆå¯åŠ¨æŒ‡ä»¤å¹¶åŠ å…¥é˜Ÿåˆ—
            start_commands = self._generate_batch_start_commands(plan_to_execute, batch_exec.batch_index)
            for cmd in start_commands:
                cmd['phase'] = 'start'
                self.command_queue.add_command(cmd)
            
            logger.info(f"æ‰¹æ¬¡ {batch_exec.batch_index} å·²ç”Ÿæˆ {len(start_commands)} æ¡å¯åŠ¨æŒ‡ä»¤")
            
            # 2. åˆå§‹åŒ–ç›‘æ§å™¨
            self._initialize_batch_monitoring(plan_to_execute, batch_exec.batch_index)
            
            # 3. å¯åŠ¨å®æ—¶ç›‘æ§å¾ªç¯
            await self._monitor_batch_until_completion(batch_exec)
            
            logger.info(f"æ‰¹æ¬¡ {batch_exec.batch_index} æ‰§è¡Œå®Œæˆ")
            
            # é€šçŸ¥çŠ¶æ€æ›´æ–°
            if self.status_update_callback:
                await self.status_update_callback(batch_exec)
                
        except Exception as e:
            batch_exec.status = BatchStatus.FAILED
            batch_exec.error_message = str(e)
            batch_exec.execution_log.append(f"æ‰§è¡Œæ‰¹æ¬¡å¤±è´¥: {e}")
            self.error_message = str(e)
            self.execution_status = "error"
            logger.error(f"æ‰§è¡Œæ‰¹æ¬¡ {batch_exec.batch_index} å¤±è´¥: {e}")
    
    async def _check_batch_completion(self, batch_exec: BatchExecution, elapsed_hours: float):
        """
        æ£€æŸ¥æ‰¹æ¬¡æ˜¯å¦å®Œæˆ
        
        Args:
            batch_exec: æ‰¹æ¬¡æ‰§è¡Œå¯¹è±¡
            elapsed_hours: å·²æ‰§è¡Œæ—¶é—´ï¼ˆå°æ—¶ï¼‰
        """
        # ç®€å•çš„æ—¶é—´åŸºç¡€å®Œæˆæ£€æŸ¥
        expected_end_time = batch_exec.original_start_time + batch_exec.original_duration
        
        if elapsed_hours >= expected_end_time:
            batch_exec.status = BatchStatus.COMPLETED
            batch_exec.completed_at = datetime.now()
            batch_exec.execution_log.append(f"æ‰¹æ¬¡ {batch_exec.batch_index} æ‰§è¡Œå®Œæˆ")
            
            logger.info(f"æ‰¹æ¬¡ {batch_exec.batch_index} æ‰§è¡Œå®Œæˆ")
            
            # é€šçŸ¥çŠ¶æ€æ›´æ–°
            if self.status_update_callback:
                await self.status_update_callback(batch_exec)
    
    def stop_execution(self) -> bool:
        """åœæ­¢æ‰§è¡Œ
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸåœæ­¢
        """
        if not self.is_running:
            self.status_manager.log_warning("scheduler", "è°ƒåº¦å™¨æœªåœ¨è¿è¡Œ")
            return False
        
        try:
            self.is_running = False
            self.status_manager.cancel_execution()
            self.status_manager.log_info("scheduler", "æ‰§è¡Œå·²åœæ­¢")
            
            return True
            
        except Exception as e:
            self.status_manager.log_error("scheduler", f"åœæ­¢æ‰§è¡Œå¤±è´¥: {str(e)}")
            return False
    
    def get_execution_status(self) -> Dict[str, Any]:
        """
        è·å–æ‰§è¡ŒçŠ¶æ€
        
        Returns:
            Dict[str, Any]: æ‰§è¡ŒçŠ¶æ€ä¿¡æ¯
        """
        # è®¡ç®—å½“å‰æ‰¹æ¬¡å’Œå®Œæˆçš„æ‰¹æ¬¡
        completed_batches = []
        active_fields = []
        
        for batch_index, batch_exec in self.batch_executions.items():
            if batch_exec.status == BatchStatus.COMPLETED:
                completed_batches.append({
                    "batch_index": batch_index,
                    "completed_at": batch_exec.completed_at.isoformat() if batch_exec.completed_at else None,
                    "duration": batch_exec.current_duration
                })
            elif batch_exec.status == BatchStatus.EXECUTING:
                self.current_batch_index = batch_index
                # ä»æ‰¹æ¬¡æ‰§è¡Œä¸­æå–æ´»è·ƒå­—æ®µä¿¡æ¯
                if hasattr(batch_exec, 'execution_plan') and batch_exec.execution_plan:
                    for field_id, field_data in batch_exec.execution_plan.items():
                        active_fields.append({
                            "field_id": field_id,
                            "status": "running",
                            "start_time": batch_exec.started_at.isoformat() if batch_exec.started_at else None
                        })
        
        return {
            "execution_id": self.execution_id or "",
            "status": self.execution_status,
            "current_batch": self.current_batch_index,
            "total_batches": len(self.batch_executions),
            "start_time": self.execution_start_time.isoformat() if self.execution_start_time else None,
            "last_water_level_update": self.last_water_level_update,
            "total_regenerations": self.total_regenerations,
            "active_fields": active_fields,
            "completed_batches": completed_batches,
            "error_message": self.error_message
        }
    
    def get_all_scenarios_info(self) -> Dict[str, Any]:
        """
        è·å–æ‰€æœ‰scenariosçš„ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: åŒ…å«æ‰€æœ‰æ–¹æ¡ˆä¿¡æ¯çš„å­—å…¸
        """
        if not self.raw_plan_data:
            return {
                "selected_scenario": None,
                "all_scenarios": [],
                "total_scenarios": 0
            }
        
        all_scenarios = []
        selected_scenario = None
        
        # æ£€æŸ¥æ˜¯å¦æœ‰scenariosç»“æ„
        if "scenarios" in self.raw_plan_data and self.raw_plan_data["scenarios"]:
            for scenario in self.raw_plan_data["scenarios"]:
                scenario_info = {
                    "scenario_name": scenario.get("scenario_name", "Unknown"),
                    "pumps_used": scenario.get("pumps_used", []),
                    "total_batches": len(scenario.get("plan", {}).get("batches", [])),
                    "total_electricity_cost": scenario.get("total_electricity_cost", 0.0),
                    "total_eta_h": scenario.get("total_eta_h", 0.0),
                    "total_pump_runtime_hours": scenario.get("total_pump_runtime_hours", 0.0),
                    "coverage_info": scenario.get("coverage_info", {})
                }
                all_scenarios.append(scenario_info)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å½“å‰é€‰ä¸­çš„æ–¹æ¡ˆ
                if scenario.get("scenario_name") == self.selected_scenario_name:
                    selected_scenario = scenario_info
        else:
            # æ—§æ ¼å¼ï¼Œåªæœ‰ä¸€ä¸ªé»˜è®¤æ–¹æ¡ˆ
            scenario_info = {
                "scenario_name": "Default Plan",
                "pumps_used": [],
                "total_batches": len(self.raw_plan_data.get("batches", [])),
                "total_electricity_cost": 0.0,
                "total_eta_h": 0.0,
                "total_pump_runtime_hours": 0.0,
                "coverage_info": {}
            }
            all_scenarios.append(scenario_info)
            selected_scenario = scenario_info
        
        return {
            "selected_scenario": selected_scenario,
            "all_scenarios": all_scenarios,
            "total_scenarios": len(all_scenarios)
        }
    
    def set_device_control_callback(self, callback: Callable):
        """è®¾ç½®è®¾å¤‡æ§åˆ¶å›è°ƒå‡½æ•°"""
        self.device_control_callback = callback
    
    def set_status_update_callback(self, callback: Callable):
        """è®¾ç½®çŠ¶æ€æ›´æ–°å›è°ƒå‡½æ•°"""
        self.status_update_callback = callback
    
    def get_current_plan(self) -> Optional[Dict[str, Any]]:
        """
        è·å–å½“å‰çš„çŒæº‰è®¡åˆ’
        
        Returns:
            Optional[Dict[str, Any]]: å½“å‰è®¡åˆ’ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        return self.current_plan

    async def update_batch_plan(self, batch_index: int, new_commands: List[Dict[str, Any]]) -> bool:
        """
        æ›´æ–°æŒ‡å®šæ‰¹æ¬¡çš„æ‰§è¡Œè®¡åˆ’
        
        Args:
            batch_index: æ‰¹æ¬¡ç´¢å¼•
            new_commands: æ–°çš„æ‰§è¡Œå‘½ä»¤åˆ—è¡¨
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            if batch_index < 0 or batch_index >= len(self.batch_executions):
                logger.error(f"æ‰¹æ¬¡ç´¢å¼• {batch_index} è¶…å‡ºèŒƒå›´")
                return False
            
            batch_exec = self.batch_executions[batch_index]
            
            # åªå…è®¸æ›´æ–°æœªå¼€å§‹æˆ–å‡†å¤‡ä¸­çš„æ‰¹æ¬¡
            if batch_exec.status not in [BatchStatus.PENDING, BatchStatus.PREPARING]:
                logger.error(f"æ‰¹æ¬¡ {batch_index} çŠ¶æ€ä¸º {batch_exec.status.value}ï¼Œæ— æ³•æ›´æ–°")
                return False
            
            # æ›´æ–°æ‰¹æ¬¡çš„æ‰§è¡Œå‘½ä»¤
            batch_exec.regenerated_commands = new_commands
            batch_exec.execution_log.append(f"æ‰¹æ¬¡è®¡åˆ’å·²æ›´æ–°ï¼Œæ–°å‘½ä»¤æ•°é‡: {len(new_commands)}")
            
            # æ›´æ–°çŠ¶æ€ç®¡ç†å™¨
            await self.status_manager.update_execution_status(
                farm_id=self.farm_id,
                batch_id=f"batch_{batch_index}",
                status="plan_updated",
                progress=0,
                message=f"æ‰¹æ¬¡ {batch_index} è®¡åˆ’å·²æ›´æ–°"
            )
            
            logger.info(f"æ‰¹æ¬¡ {batch_index} è®¡åˆ’æ›´æ–°æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"æ›´æ–°æ‰¹æ¬¡ {batch_index} è®¡åˆ’å¤±è´¥: {e}")
            return False

    def get_execution_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–æ‰§è¡Œå†å²
        
        Args:
            limit: è¿”å›è®°å½•æ•°é™åˆ¶
            
        Returns:
            List[Dict[str, Any]]: æ‰§è¡Œå†å²åˆ—è¡¨
        """
        try:
            # ä»çŠ¶æ€ç®¡ç†å™¨è·å–æ‰§è¡Œå†å²
            logs = self.status_manager.get_execution_logs(
                farm_id=self.farm_id,
                limit=limit
            )
            
            # è½¬æ¢ä¸ºAPIå“åº”æ ¼å¼
            history = []
            for log in logs:
                history_item = {
                    "execution_id": log.get("batch_id", ""),
                    "farm_id": self.farm_id,
                    "status": log.get("status", "unknown"),
                    "start_time": log.get("timestamp", ""),
                    "end_time": log.get("end_time", ""),
                    "total_batches": len(self.batch_executions) if self.batch_executions else 0,
                    "completed_batches": log.get("progress", 0),
                    "error_message": log.get("error_message", ""),
                    "message": log.get("message", "")
                }
                history.append(history_item)
            
            return history
            
        except Exception as e:
            logger.error(f"è·å–æ‰§è¡Œå†å²å¤±è´¥: {e}")
            return []
    
    def get_field_trend_analysis(self, field_id: str, days: int = 7) -> Dict[str, Any]:
        """
        è·å–ç”°å—æ°´ä½è¶‹åŠ¿åˆ†æ
        
        Args:
            field_id: ç”°å—ID
            days: åˆ†æå¤©æ•°
            
        Returns:
            Dict[str, Any]: è¶‹åŠ¿åˆ†æç»“æœ
        """
        try:
            # ä»æ°´ä½ç®¡ç†å™¨è·å–è¶‹åŠ¿åˆ†æ
            if hasattr(self, 'waterlevel_manager') and self.waterlevel_manager:
                analysis = self.waterlevel_manager.get_field_trend_analysis(field_id, days * 24)  # è½¬æ¢ä¸ºå°æ—¶
                return analysis
            else:
                # è¿”å›åŸºæœ¬çš„å“åº”
                return {
                    "field_id": field_id,
                    "analysis_period_days": days,
                    "trend_direction": "stable",
                    "average_level_mm": 0.0,
                    "min_level_mm": 0.0,
                    "max_level_mm": 0.0,
                    "data_points_count": 0,
                    "confidence": 0.0,
                    "last_update": datetime.now().isoformat(),
                    "message": "æ°´ä½ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œè¿”å›é»˜è®¤æ•°æ®"
                }
                
        except Exception as e:
            logger.error(f"è·å–ç”°å— {field_id} è¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
            return {
                "field_id": field_id,
                "analysis_period_days": days,
                "error": str(e),
                "message": "è¶‹åŠ¿åˆ†æå¤±è´¥"
            }

    async def get_batch_details(self, batch_index: int) -> Optional[Dict[str, Any]]:
        """
        è·å–æ‰¹æ¬¡è¯¦ç»†ä¿¡æ¯
        
        Args:
            batch_index: æ‰¹æ¬¡ç´¢å¼•
            
        Returns:
            Optional[Dict[str, Any]]: æ‰¹æ¬¡è¯¦ç»†ä¿¡æ¯
        """
        try:
            if batch_index < 0 or batch_index >= len(self.batch_executions):
                return None
            
            batch_exec = self.batch_executions[batch_index]
            
            # è·å–æ‰¹æ¬¡è¯¦ç»†ä¿¡æ¯
            details = await self.status_manager.get_batch_details(f"batch_{batch_index}")
            
            # æ„å»ºå“åº”
            batch_details = {
                "batch_index": batch_index,
                "status": batch_exec.status.value,
                "start_time": batch_exec.start_time.isoformat() if batch_exec.start_time else None,
                "duration_minutes": batch_exec.duration_minutes,
                "original_commands_count": len(batch_exec.original_commands) if batch_exec.original_commands else 0,
                "regenerated_commands_count": len(batch_exec.regenerated_commands) if batch_exec.regenerated_commands else 0,
                "water_levels_count": len(batch_exec.water_levels) if batch_exec.water_levels else 0,
                "execution_log": batch_exec.execution_log,
                "database_details": details
            }
            
            return batch_details
            
        except Exception as e:
            logger.error(f"è·å–æ‰¹æ¬¡ {batch_index} è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
            return None

    def get_farm_id(self) -> str:
        """è·å–å†œåœºID"""
        return self.farm_id

    async def cleanup_old_data(self, retention_days: int = 30):
        """
        æ¸…ç†æ—§æ•°æ®
        
        Args:
            retention_days: æ•°æ®ä¿ç•™å¤©æ•°
        """
        try:
            await self.status_manager.cleanup_old_data(retention_days)
            logger.info(f"æ¸…ç† {retention_days} å¤©å‰çš„æ—§æ•°æ®å®Œæˆ")
        except Exception as e:
            logger.error(f"æ¸…ç†æ—§æ•°æ®å¤±è´¥: {e}")
    
    def _generate_batch_start_commands(self, plan: Dict[str, Any], batch_index: int) -> List[Dict]:
        """
        ç”Ÿæˆæ‰¹æ¬¡å¯åŠ¨æŒ‡ä»¤
        
        Args:
            plan: æ‰¹æ¬¡è®¡åˆ’ï¼ˆå¯èƒ½æ˜¯å®Œæ•´è®¡åˆ’æˆ–å•ä¸ªæ‰¹æ¬¡ï¼‰
            batch_index: æ‰¹æ¬¡ç´¢å¼•
        
        Returns:
            List[Dict]: æŒ‡ä»¤åˆ—è¡¨
        """
        commands = []
        
        # æå–æ­¥éª¤å’Œç”°å—åˆ—è¡¨ - å…¼å®¹ä¸¤ç§æ ¼å¼
        steps_list = []
        fields_list = []
        
        # æ ¼å¼1ï¼šplanç›´æ¥åŒ…å«stepså’Œfieldsï¼ˆå•ä¸ªæ‰¹æ¬¡æ ¼å¼ï¼‰
        if 'steps' in plan:
            steps_list = plan.get('steps', [])
        if 'fields' in plan and plan['fields']:
            fields_list = plan['fields']
        
        # æ ¼å¼2ï¼šplanåŒ…å«batchesæ•°ç»„ï¼ˆå®Œæ•´è®¡åˆ’æ ¼å¼ï¼‰
        if 'batches' in plan:
            # ä»batchesä¸­æ‰¾åˆ°å¯¹åº”æ‰¹æ¬¡
            for batch in plan['batches']:
                if batch.get('index') == batch_index:
                    fields_list = batch.get('fields', [])
                    break
            # ä»stepsä¸­æ‰¾åˆ°å¯¹åº”æ‰¹æ¬¡çš„step
            all_steps = plan.get('steps', [])
            batch_label = f"æ‰¹æ¬¡ {batch_index}"
            for step in all_steps:
                if step.get('label') == batch_label:
                    steps_list = [step]
                    break
        
        # 1. æ³µç«™å¯åŠ¨æŒ‡ä»¤
        for step in steps_list:
            pumps_on = step.get('sequence', {}).get('pumps_on', [])
            for pump_id in pumps_on:
                # ä»é…ç½®æ•°æ®ä¸­æŸ¥æ‰¾æ³µç«™çš„unique_no
                pump_unique_no = self._get_pump_unique_no(pump_id)
                commands.append({
                    "device_type": "pump",
                    "device_id": pump_id,
                    "unique_no": pump_unique_no,
                    "action": "start",
                    "params": {},
                    "priority": 1,
                    "description": f"å¯åŠ¨{pump_id}æ³µç«™"
                })
        
        # 2. èŠ‚åˆ¶é—¸å¼€å¯æŒ‡ä»¤
        for step in steps_list:
            gates_set = step.get('sequence', {}).get('gates_set', [])
            for gate in gates_set:
                if gate.get('open_pct', 0) > 0:
                    commands.append({
                        "device_type": "regulator",
                        "device_id": gate['id'],
                        "unique_no": gate.get('unique_no'),
                        "action": "open",
                        "params": {"open_pct": gate['open_pct'], "gate_degree": gate['open_pct']},
                        "priority": 2,
                        "description": f"å¼€å¯{gate['id']}èŠ‚åˆ¶é—¸({gate['open_pct']}%)"
                    })
        
        # 3. ç”°å—è¿›æ°´é˜€å¼€å¯æŒ‡ä»¤
        for field in fields_list:
            commands.append({
                "device_type": "field_inlet_gate",
                "device_id": field['id'],
                "unique_no": field.get('inlet_unique_no'),
                "action": "open",
                "params": {"gate_degree": 100},
                "priority": 3,
                "description": f"å¼€å¯{field['id']}è¿›æ°´é˜€"
            })
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        commands.sort(key=lambda x: x['priority'])
        
        return commands
    
    def _get_pump_unique_no(self, pump_id: str) -> Optional[str]:
        """
        ä»é…ç½®æ•°æ®ä¸­è·å–æ³µç«™çš„unique_no
        
        Args:
            pump_id: æ³µç«™IDï¼ˆå¦‚ "P1"ï¼‰
        
        Returns:
            Optional[str]: æ³µç«™çš„unique_noï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å›None
        """
        try:
            pumps = self.config_data.get('pumps', [])
            for pump in pumps:
                if pump.get('id') == pump_id:
                    return pump.get('unique_no')
            
            logger.warning(f"æœªæ‰¾åˆ°æ³µç«™ {pump_id} çš„unique_no")
            return None
        except Exception as e:
            logger.error(f"è·å–æ³µç«™unique_noå¤±è´¥: {e}")
            return None
    
    def _initialize_batch_monitoring(self, plan: Dict[str, Any], batch_index: int):
        """
        åˆå§‹åŒ–æ‰¹æ¬¡ç›‘æ§
        
        Args:
            plan: æ‰¹æ¬¡è®¡åˆ’ï¼ˆå¯èƒ½æ˜¯å®Œæ•´è®¡åˆ’æˆ–å•ä¸ªæ‰¹æ¬¡ï¼‰
            batch_index: æ‰¹æ¬¡ç´¢å¼•
        """
        # å»¶è¿Ÿåˆå§‹åŒ–ç›‘æ§å™¨
        if self.completion_monitor is None:
            from .field_completion_monitor import FieldCompletionMonitor
            self.completion_monitor = FieldCompletionMonitor(
                config_data=self.config_data,
                app_id=self.app_id,
                secret=self.secret,
                check_interval=30
            )
        
        # æå–ç”°å—ä¿¡æ¯ - å…¼å®¹ä¸¤ç§æ ¼å¼
        batch_fields = []
        fields_list = []
        
        # æ ¼å¼1ï¼šplanç›´æ¥åŒ…å«fieldsï¼ˆå•ä¸ªæ‰¹æ¬¡æ ¼å¼ï¼‰
        if 'fields' in plan and plan['fields']:
            fields_list = plan['fields']
        # æ ¼å¼2ï¼šplanåŒ…å«batchesæ•°ç»„ï¼ˆå®Œæ•´è®¡åˆ’æ ¼å¼ï¼‰
        elif 'batches' in plan:
            for batch in plan['batches']:
                if batch.get('index') == batch_index:
                    fields_list = batch.get('fields', [])
                    break
        
        for field in fields_list:
            batch_fields.append({
                'id': field['id'],
                'segment_id': field.get('segment_id', ''),
                'inlet_gid': field.get('inlet_G_id', ''),
                'wl_mm': field.get('wl_mm', 0.0),
                'wl_opt': field.get('wl_opt', 50.0),
                'wl_high': field.get('wl_high', 80.0),
                'inlet_unique_no': field.get('inlet_unique_no', ''),
                'outlet_unique_no': field.get('outlet_unique_no', None)
            })
        
        # æå–èŠ‚åˆ¶é—¸ä¿¡æ¯
        batch_regulators = []
        for step in plan.get('steps', []):
            for gate in step.get('sequence', {}).get('gates_set', []):
                if gate.get('open_pct', 0) > 0:
                    segment_id = self._extract_segment_from_gate_id(gate['id'])
                    batch_regulators.append({
                        'id': gate['id'],
                        'type': gate.get('type', 'branch-g'),
                        'segment_id': segment_id,
                        'unique_no': gate.get('unique_no', None),
                        'open_pct': gate['open_pct']
                    })
        
        # æå–æ³µç«™ä¿¡æ¯
        batch_pumps = []
        for step in plan.get('steps', []):
            pumps_on = step.get('sequence', {}).get('pumps_on', [])
            batch_pumps.extend(pumps_on)
        
        # å»é‡
        batch_pumps = list(set(batch_pumps))
        
        # åˆå§‹åŒ–ç›‘æ§å™¨
        self.completion_monitor.initialize_batch(
            batch_fields=batch_fields,
            batch_regulators=batch_regulators,
            batch_pumps=batch_pumps
        )
        
        logger.info(f"æ‰¹æ¬¡ {batch_index} ç›‘æ§åˆå§‹åŒ–å®Œæˆ: "
                   f"{len(batch_fields)}ç”°å—, {len(batch_regulators)}èŠ‚åˆ¶é—¸, {len(batch_pumps)}æ³µç«™")
    
    async def _monitor_batch_until_completion(self, batch_exec: BatchExecution):
        """
        å®æ—¶ç›‘æ§ç›´åˆ°æ‰¹æ¬¡å®Œæˆ
        
        Args:
            batch_exec: æ‰¹æ¬¡æ‰§è¡Œå¯¹è±¡
        """
        check_count = 0
        max_duration_hours = batch_exec.original_duration * 2  # è¶…æ—¶ä¿æŠ¤ï¼šé¢„è®¡æ—¶é—´çš„2å€
        max_checks = int(max_duration_hours * 3600 / 30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
        no_data_count = 0  # æ— æ°´ä½æ•°æ®è®¡æ•°å™¨
        
        logger.info(f"æ‰¹æ¬¡ {batch_exec.batch_index} å¼€å§‹å®æ—¶ç›‘æ§ï¼ˆé¢„è®¡ {batch_exec.original_duration:.2f}hï¼‰")
        logger.info(f"ğŸ’¡ æç¤ºï¼šç³»ç»Ÿå°†æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡æ°´ä½ï¼Œè‡ªåŠ¨å…³é—­è¾¾æ ‡è®¾å¤‡")
        
        while check_count < max_checks:
            check_count += 1
            
            # 1. è·å–æœ€æ–°æ°´ä½
            latest_wl = await self._fetch_current_water_levels()
            
            if not latest_wl:
                no_data_count += 1
                # åªåœ¨ç¬¬1æ¬¡å’Œæ¯10æ¬¡æ—¶è¾“å‡ºè­¦å‘Šï¼Œé¿å…æ—¥å¿—è¿‡å¤š
                if no_data_count == 1:
                    logger.warning(f"âš ï¸ æœªè·å–åˆ°å®æ—¶æ°´ä½æ•°æ®ï¼Œå°†ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„åˆå§‹æ°´ä½ç»§ç»­ç›‘æ§")
                elif no_data_count % 10 == 0:
                    logger.debug(f"å·²å°è¯• {no_data_count} æ¬¡ï¼Œä»æœªè·å–åˆ°æ°´ä½æ•°æ®")
                await asyncio.sleep(30)
                continue
            else:
                # æˆåŠŸè·å–æ•°æ®åé‡ç½®è®¡æ•°å™¨
                if no_data_count > 0:
                    logger.info(f"âœ… å·²æ¢å¤æ°´ä½æ•°æ®è·å–")
                    no_data_count = 0
            
            # 2. æ£€æŸ¥å¹¶ç”Ÿæˆå…³é—­æŒ‡ä»¤
            result = await self.completion_monitor.check_and_close_devices(latest_wl)
            
            # 3. å°†å…³é—­æŒ‡ä»¤åŠ å…¥é˜Ÿåˆ—
            if result['completed_fields']:
                for field_id in result['completed_fields']:
                    field_info = self.completion_monitor.active_fields.get(field_id)
                    if field_info:
                        close_cmd = {
                            "device_type": "field_inlet_gate",
                            "device_id": field_id,
                            "unique_no": field_info.inlet_device,
                            "action": "close",
                            "params": {"gate_degree": 0},
                            "priority": 1,
                            "phase": "running",
                            "reason": f"æ°´ä½è¾¾æ ‡({field_info.current_wl:.1f}mm)",
                            "description": f"å…³é—­{field_id}è¿›æ°´é˜€"
                        }
                        self.command_queue.add_command(close_cmd)
            
            if result['closed_regulators']:
                for reg_id in result['closed_regulators']:
                    reg_info = self.completion_monitor.active_regulators.get(reg_id)
                    if reg_info:
                        close_cmd = {
                            "device_type": "regulator",
                            "device_id": reg_id,
                            "unique_no": reg_info.unique_no,
                            "action": "close",
                            "params": {"gate_degree": 0, "open_pct": 0},
                            "priority": 2,
                            "phase": "running",
                            "reason": f"æ”¯æ¸ {reg_info.segment_id}æ‰€æœ‰ç”°å—å·²å®Œæˆ",
                            "description": f"å…³é—­{reg_id}èŠ‚åˆ¶é—¸"
                        }
                        self.command_queue.add_command(close_cmd)
            
            if result['stopped_pumps']:
                for pump_id in result['stopped_pumps']:
                    pump_unique_no = self._get_pump_unique_no(pump_id)
                    stop_cmd = {
                        "device_type": "pump",
                        "device_id": pump_id,
                        "unique_no": pump_unique_no,
                        "action": "stop",
                        "params": {},
                        "priority": 3,
                        "phase": "running",
                        "reason": "æ‰€æœ‰æ‰¹æ¬¡å®Œæˆ",
                        "description": f"åœæ­¢{pump_id}æ³µç«™"
                    }
                    self.command_queue.add_command(stop_cmd)
            
            # 4. æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if result['all_completed']:
                batch_exec.status = BatchStatus.COMPLETED
                batch_exec.completed_at = datetime.now()
                
                actual_duration = (batch_exec.completed_at - batch_exec.started_at).total_seconds() / 3600
                logger.info(f"âœ… æ‰¹æ¬¡ {batch_exec.batch_index} å®Œæˆï¼")
                logger.info(f"  é¢„è®¡æ—¶é—´: {batch_exec.original_duration:.2f}h")
                logger.info(f"  å®é™…æ—¶é—´: {actual_duration:.2f}h")
                logger.info(f"  å®Œæˆç”°å—: {len(result['completed_fields'])}")
                break
            
            # 5. æ˜¾ç¤ºè¿›åº¦
            if self.completion_monitor:
                stats = self.completion_monitor.get_statistics()
                progress = (stats['completed_fields'] / stats['total_fields']) * 100 if stats['total_fields'] > 0 else 0
                logger.info(f"æ‰¹æ¬¡ {batch_exec.batch_index} è¿›åº¦: {progress:.0f}% "
                           f"({stats['completed_fields']}/{stats['total_fields']} ç”°å—)")
            
            # 6. ç­‰å¾…30ç§’åç»§ç»­
            await asyncio.sleep(30)
        
        # è¶…æ—¶ä¿æŠ¤
        if check_count >= max_checks:
            logger.warning(f"æ‰¹æ¬¡ {batch_exec.batch_index} è¶…æ—¶ï¼ˆå·²æ£€æŸ¥{check_count}æ¬¡ï¼‰ï¼Œå¼ºåˆ¶å®Œæˆ")
            batch_exec.status = BatchStatus.COMPLETED
            batch_exec.completed_at = datetime.now()
    
    @staticmethod
    def _extract_segment_from_gate_id(gate_id: str) -> str:
        """ä»é—¸é—¨IDæå–æ”¯æ¸ IDï¼Œå¦‚ S3-G2 â†’ S3"""
        if '-G' in gate_id:
            return gate_id.split('-G')[0]
        return gate_id
    
    async def _fetch_current_water_levels(self) -> Dict[str, float]:
        """
        è·å–å½“å‰æœ€æ–°æ°´ä½æ•°æ®
        
        Returns:
            Dict[str, float]: ç”°å—IDåˆ°æ°´ä½(mm)çš„æ˜ å°„
        """
        try:
            from src.api.waterlevel_api import fetch_waterlevels
            
            # è°ƒç”¨æ°´ä½APIè·å–æœ€æ–°æ•°æ®ï¼ˆåªéœ€è¦farm_idï¼‰
            response = fetch_waterlevels(farm_id=self.farm_id)
            
            if not response:
                # ä½¿ç”¨DEBUGçº§åˆ«ï¼Œé¿å…è¿‡å¤šè­¦å‘Šä¿¡æ¯
                logger.debug(f"æ°´ä½APIæœªè¿”å›æ•°æ®ï¼ˆfarm_id={self.farm_id}ï¼‰ï¼Œå°†ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„åˆå§‹æ°´ä½")
                return {}
            
            # è§£ææ°´ä½æ•°æ®
            water_levels = {}
            for item in response:
                # waterlevel_api è¿”å›æ ¼å¼: {"sectionID": str, "sectionCode": str, "waterlevel_mm": float}
                section_code = item.get('sectionCode')
                wl_mm = item.get('waterlevel_mm')
                if section_code and wl_mm is not None:
                    water_levels[section_code] = wl_mm
            
            logger.info(f"âœ… è·å–åˆ° {len(water_levels)} ä¸ªç”°å—çš„å®æ—¶æ°´ä½æ•°æ®")
            return water_levels
            
        except Exception as e:
            logger.debug(f"è·å–æ°´ä½æ•°æ®å¼‚å¸¸: {e}ï¼Œå°†ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„åˆå§‹æ°´ä½")
            return {}

# ç¤ºä¾‹è®¾å¤‡æ§åˆ¶å›è°ƒå‡½æ•°
async def example_device_control_callback(batch_exec: BatchExecution, plan: Dict[str, Any]):
    """
    ç¤ºä¾‹è®¾å¤‡æ§åˆ¶å›è°ƒå‡½æ•°
    
    Args:
        batch_exec: æ‰¹æ¬¡æ‰§è¡Œå¯¹è±¡
        plan: æ‰§è¡Œè®¡åˆ’
    """
    logger.info(f"æ‰§è¡Œæ‰¹æ¬¡ {batch_exec.batch_index} çš„è®¾å¤‡æ§åˆ¶")
    
    # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„è®¾å¤‡æ§åˆ¶é€»è¾‘
    # ä¾‹å¦‚ï¼šå¯åŠ¨æ°´æ³µã€å¼€å…³é˜€é—¨ç­‰
    
    # æ¨¡æ‹Ÿæ‰§è¡Œæ—¶é—´
    await asyncio.sleep(1)
    
    batch_exec.execution_log.append("è®¾å¤‡æ§åˆ¶å‘½ä»¤å·²å‘é€")

# ç¤ºä¾‹çŠ¶æ€æ›´æ–°å›è°ƒå‡½æ•°
async def example_status_update_callback(batch_exec: BatchExecution):
    """
    ç¤ºä¾‹çŠ¶æ€æ›´æ–°å›è°ƒå‡½æ•°
    
    Args:
        batch_exec: æ‰¹æ¬¡æ‰§è¡Œå¯¹è±¡
    """
    logger.info(f"æ‰¹æ¬¡ {batch_exec.batch_index} çŠ¶æ€æ›´æ–°: {batch_exec.status.value}")

if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    async def main():
        # åˆ›å»ºè°ƒåº¦å™¨
        scheduler = BatchExecutionScheduler(
            config_path="config.json",
            farm_id="gzp_farm",
            enable_realtime_waterlevels=True,
            pre_execution_buffer_minutes=5
        )
        
        # è®¾ç½®å›è°ƒå‡½æ•°
        scheduler.set_device_control_callback(example_device_control_callback)
        scheduler.set_status_update_callback(example_status_update_callback)
        
        # åŠ è½½çŒæº‰è®¡åˆ’
        if scheduler.load_irrigation_plan("output/irrigation_plan_latest.json"):
            # å¼€å§‹æ‰§è¡Œ
            await scheduler.start_execution()
        else:
            logger.error("æ— æ³•åŠ è½½çŒæº‰è®¡åˆ’")
    
    # è¿è¡Œç¤ºä¾‹
    asyncio.run(main())